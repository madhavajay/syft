{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syftbox.lib import config_for_user, syftbox_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_config = config_for_user(\"madhava@openmined.org\")\n",
    "client_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_config.use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = client_config.get_datasets()\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix = datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syftbox.lib.david.rolle.at.gmail.com.datasets import netflix_tmdb_imdb\n",
    "\n",
    "netflix_tmdb_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syftbox.lib.me.at.madhavajay.com.datasets import netflix_tmdb_imdb\n",
    "\n",
    "netflix_tmdb_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_folder():\n",
    "    import shutil\n",
    "\n",
    "    try:\n",
    "        shutil.rmtree(\"./crypto/data\")\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# private\n",
    "def create_and_get_he_context():\n",
    "    import os\n",
    "\n",
    "    from Pyfhel import Pyfhel\n",
    "\n",
    "    crypto_folder = \"./crypto\"\n",
    "    os.makedirs(crypto_folder, exist_ok=True)\n",
    "    HE = Pyfhel()\n",
    "    if os.path.exists(\"crypto/pyfhel.secret\"):\n",
    "        print(\"Loading HE keys\")\n",
    "        HE.load_context(f\"{crypto_folder}/pyfhel.context\")\n",
    "        HE.load_secret_key(f\"{crypto_folder}/pyfhel.secret\")\n",
    "        HE.load_public_key(f\"{crypto_folder}/pyfhel.pk\")\n",
    "    else:\n",
    "        print(\"Generating new HE keys\")\n",
    "        HE.contextGen(scheme=\"bfv\", n=2**15, t_bits=20)\n",
    "        HE.keyGen()\n",
    "        HE.save_secret_key(\"crypto/pyfhel.secret\")\n",
    "        HE.save_public_key(\"crypto/pyfhel.pk\")\n",
    "        HE.save_context(\"crypto/pyfhel.context\")\n",
    "\n",
    "    return HE\n",
    "\n",
    "\n",
    "HE = create_and_get_he_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# private\n",
    "def create_he_data(HE):\n",
    "    import os\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    crypto_folder = \"./crypto\"\n",
    "    stats_keys = [\n",
    "        \"total_time\",\n",
    "        \"total_views\",\n",
    "        \"total_unique_show_views\",\n",
    "        # \"year_fav_day\"\n",
    "    ]\n",
    "\n",
    "    stat_folder = f\"./{crypto_folder}/data\"\n",
    "    part_path = f\"{stat_folder}/totals\"\n",
    "    slice_folder = f\"{stat_folder}/view_counts\"\n",
    "    os.makedirs(stat_folder, exist_ok=True)\n",
    "    os.makedirs(slice_folder, exist_ok=True)\n",
    "\n",
    "    # create totals\n",
    "    stats_array = np.zeros(len(stats_keys)).astype(int)\n",
    "    value = HE.encryptInt(stats_array)\n",
    "    value.save(part_path)\n",
    "\n",
    "    max_tv_id = 300_000  # just a guess\n",
    "    slice_size = 30_000  # max size of the above HE context\n",
    "\n",
    "    # create imdb_id slices\n",
    "    counter = 0\n",
    "    for i in range(0, max_tv_id + 1, slice_size):\n",
    "        tv_count_array = np.zeros(slice_size).astype(int)\n",
    "        tv_count_slice = HE.encryptInt(tv_count_array)\n",
    "        part_path = f\"{slice_folder}/tmdb_id_{counter:02}\"\n",
    "        tv_count_slice.save(part_path)\n",
    "        counter += 1\n",
    "    print(\"HE Data Created\")\n",
    "\n",
    "\n",
    "reset_folder()\n",
    "create_he_data(HE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# public federated code\n",
    "@syftbox_code\n",
    "def netflix_stats(datasite, df):\n",
    "    import datetime\n",
    "    import os\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from Pyfhel import PyCtxt, Pyfhel\n",
    "\n",
    "    crypto_folder = \"./crypto\"\n",
    "    completed_sentinel = f\"{crypto_folder}/{datasite}\"\n",
    "    if os.path.exists(completed_sentinel):\n",
    "        print(\"‚úÖ Already generated üîê Homomorphically Encrypted Stats\")\n",
    "        return\n",
    "\n",
    "    HE = Pyfhel()\n",
    "    HE.load_context(f\"{crypto_folder}/pyfhel.context\")\n",
    "    HE.load_secret_key(f\"{crypto_folder}/pyfhel.secret\")\n",
    "    HE.load_public_key(f\"{crypto_folder}/pyfhel.pk\")\n",
    "\n",
    "    current_year = datetime.datetime.now().year\n",
    "    df[\"netflix_date\"] = pd.to_datetime(df[\"netflix_date\"])\n",
    "    year_df = df[df[\"netflix_date\"].dt.year == current_year]\n",
    "    year_tv_df = year_df[year_df[\"tmdb_media_type\"] == \"tv\"]\n",
    "    year_tv_df[\"day_of_week\"] = year_tv_df[\"netflix_date\"].dt.day_name()\n",
    "    total_time = year_tv_df[\"imdb_runtime_minutes\"].sum()\n",
    "    total_views = len(year_tv_df)\n",
    "    total_unique_show_views = year_tv_df[\"imdb_id\"].nunique()\n",
    "    # day_counts = year_tv_df[\"day_of_week\"].value_counts()\n",
    "    # favorite_day = list(day_counts.to_dict().keys())[0]\n",
    "    # year_tv_df[\"day_of_week\"] = year_tv_df[\"netflix_date\"].dt.weekday\n",
    "    # change to an int as a numpy array so we can add them\n",
    "\n",
    "    value_counts = year_tv_df[\"tmdb_id\"].value_counts().astype(int)\n",
    "\n",
    "    stats = {\n",
    "        \"total_time\": int(total_time),\n",
    "        \"total_views\": int(total_views),\n",
    "        \"total_unique_show_views\": int(total_unique_show_views),\n",
    "        # \"year_fav_day\": str(favorite_day),\n",
    "    }\n",
    "\n",
    "    stat_folder = f\"./{crypto_folder}/data\"\n",
    "    part_path = f\"{stat_folder}/totals\"\n",
    "    slice_folder = f\"{stat_folder}/view_counts\"\n",
    "    exists_files_folders = [stat_folder, part_path, slice_folder]\n",
    "\n",
    "    for path in exists_files_folders:\n",
    "        if not os.path.abspath(path):\n",
    "            raise Exception(f\"Requires {stat_folder} to finish syncing\")\n",
    "\n",
    "    imdb_id_files = os.listdir(slice_folder)\n",
    "    if len(imdb_id_files) < 10:\n",
    "        raise Exception(f\"Requires {slice_folder} to finish syncing\")\n",
    "\n",
    "    # write stats to encrypted array\n",
    "    stats_array = np.zeros(len(stats)).astype(int)\n",
    "    for i, value in enumerate(stats.values()):\n",
    "        stats_array[i] = int(value)\n",
    "\n",
    "    value = PyCtxt(pyfhel=HE)\n",
    "    value.load(part_path)\n",
    "    value += stats_array\n",
    "    value.save(part_path)\n",
    "\n",
    "    slice_size = 30_000  # max size of the above HE context\n",
    "\n",
    "    # write imdb_id value counts to chunked arrays\n",
    "    for k, v in value_counts.items():\n",
    "        imdb_id = int(k)\n",
    "        index = imdb_id // slice_size\n",
    "        sub_index = imdb_id % slice_size\n",
    "        tv_count_slice = PyCtxt(pyfhel=HE)\n",
    "        part_path = f\"{slice_folder}/tmdb_id_{index:02}\"\n",
    "        empty_array = np.zeros(slice_size).astype(int)\n",
    "        empty_array[sub_index] += int(v)\n",
    "        tv_count_slice.load(part_path)\n",
    "        tv_count_slice += empty_array\n",
    "        tv_count_slice.save(part_path)\n",
    "\n",
    "    with open(f\"{crypto_folder}/{datasite}\", \"w\") as f:\n",
    "        print(\"‚úÖ Writing üîê Homomorphically Encrypted Stats\")\n",
    "        f.write(str(datetime.datetime.now()))\n",
    "\n",
    "\n",
    "# netflix_stats(\"me@madhavajay.com\", netflix_tmdb_imdb.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_results(HE, stat_keys, path):\n",
    "    import numpy as np\n",
    "    from Pyfhel import PyCtxt\n",
    "\n",
    "    crypto_folder = path + \"/crypto\"\n",
    "    stat_folder = f\"./{crypto_folder}/data\"\n",
    "    part_path = f\"{stat_folder}/totals\"\n",
    "    slice_folder = f\"{stat_folder}/view_counts\"\n",
    "\n",
    "    # decode stats\n",
    "    value = PyCtxt(pyfhel=HE)\n",
    "    part_path = f\"{stat_folder}/totals\"\n",
    "    value.load(part_path)\n",
    "    value_array = HE.decryptInt(value)\n",
    "    stats = {}\n",
    "    for i, key in enumerate(stats_keys):\n",
    "        stats[key] = int(value_array[i])\n",
    "\n",
    "    tmdb_id_value_counts = {}\n",
    "    max_tv_id = 300_000  # just a guess\n",
    "    slice_size = 30_000  # max size of the above HE context\n",
    "    counter = 0\n",
    "    for i in range(0, max_tv_id + 1, slice_size):\n",
    "        part_path = f\"{slice_folder}/tmdb_id_{counter:02}\"\n",
    "        tv_count_slice = PyCtxt(pyfhel=HE)\n",
    "        tv_count_slice.load(part_path)\n",
    "        tv_count_array = HE.decryptInt(tv_count_slice)\n",
    "\n",
    "        non_zero_indices = np.nonzero(tv_count_array)[0].astype(int)\n",
    "        non_zero_values = tv_count_array[non_zero_indices].astype(int)\n",
    "        outer_part = counter * slice_size\n",
    "        non_zero_dict = {int(k + outer_part): int(v) for k, v in dict(zip(non_zero_indices, non_zero_values)).items()}\n",
    "        tmdb_id_value_counts.update(non_zero_dict)\n",
    "        counter += 1\n",
    "        stats[\"value_counts\"] = dict(sorted(tmdb_id_value_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "    return stats\n",
    "\n",
    "\n",
    "stats_keys = [\n",
    "    \"total_time\",\n",
    "    \"total_views\",\n",
    "    \"total_unique_show_views\",\n",
    "    # \"year_fav_day\"\n",
    "]\n",
    "all_results = decode_results(HE, stats_keys, \"./\")\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_summary(all_results, num_parties, top_k=5):\n",
    "    top_5_summary = {}\n",
    "    top_5_summary[\"avg_time\"] = round(all_results[\"total_time\"] / num_parties)\n",
    "    top_5_summary[\"avg_views\"] = round(all_results[\"total_views\"] / num_parties)\n",
    "    top_5_summary[\"avg_unique_show_views\"] = round(all_results[\"total_unique_show_views\"] / num_parties)\n",
    "    top_5_summary[\"top_5\"] = dict(\n",
    "        sorted(all_results[\"value_counts\"].items(), key=lambda item: item[1], reverse=True)[:top_k]\n",
    "    )\n",
    "    return top_5_summary\n",
    "\n",
    "\n",
    "top_k_summary(all_results, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = [dataset for dataset in datasets]\n",
    "type(dataset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list[1].syft_link.datasite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = netflix_stats.to_flow(client_config=client_config, inputs={\"dfs\": dataset_list})\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
